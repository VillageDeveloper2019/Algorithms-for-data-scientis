{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### @Author:  Marktus A Atanga\n",
    "#### Johns Hopkins University\n",
    "#### Algorithms for Data Scientists\n",
    "#### Home Work 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sys\n",
    "import itertools\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn import cluster, datasets, mixture\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.datasets import make_spd_matrix\n",
    "plt.rcParams[\"axes.grid\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem number 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m=  [[2.5]\n",
      " [2.5]] \n",
      " sigma =  [[1.73205081]\n",
      " [0.57735027]] K =  2\n",
      "\u001b[1m \u001b[91m \u001b[4mInitial values:  \n",
      "\u001b[0m\n",
      "K =  2 \n",
      "\n",
      " x=  [[1 2]\n",
      " [4 2]\n",
      " [1 3]\n",
      " [4 3]] \n",
      "\n",
      " mean =  [[2.17660879 3.75710516]\n",
      " [2.39220293 2.91903505]] \n",
      "\n",
      " sigma =  [[1.15470054 1.15470054]] \n",
      "\n",
      " prob =  [[0.5 0.5]] \n",
      "\n",
      "\n",
      "\u001b[1m \u001b[91m \u001b[4mexpectation part of the algorithm\n",
      " \u001b[0m\n",
      "expfunc=  [0.04211525 0.71258309 0.05766707 0.97571723] \n",
      "\n",
      " g=  [[0.06704469 0.03238609 0.0618376  0.0298708 ]\n",
      " [0.00502714 0.08505834 0.0068835  0.11646766]] \n",
      "\n",
      " prob=  [[0.5 0.5]] \n",
      "\n",
      " probKg=  [[0.03352234 0.01619305 0.0309188  0.0149354 ]\n",
      " [0.00251357 0.04252917 0.00344175 0.05823383]] \n",
      "\n",
      " prob_ikn=   [[0.93024822 0.27575674 0.89983427 0.20412131]\n",
      " [0.06975178 0.72424326 0.10016573 0.79587869]] \n",
      "\n",
      "\n",
      "\u001b[1m \u001b[91m \u001b[4mmaximization part of the algorithm\n",
      "\u001b[0m\n",
      "mean =  [[1.62322889 3.69837833]\n",
      " [2.47791101 2.53019142]] \n",
      "\n",
      " sigma =  [[0.93026461 0.72903287]] \n",
      "\n",
      " prob =  [[0.57749013 0.42250987]] \n",
      "\n",
      " prob_ikn =  [[0.93024822 0.27575674 0.89983427 0.20412131]\n",
      " [0.06975178 0.72424326 0.10016573 0.79587869]]\n",
      "meanPrevious =  [[1.62322889 3.69837833]\n",
      " [2.47791101 2.53019142]]\n",
      "converge =  1\n",
      "\u001b[1m \u001b[91m \u001b[4mexpectation part of the algorithm\n",
      " \u001b[0m\n",
      "expfunc=  [0.00081339 0.70466401 0.00086093 0.74585146] \n",
      "\n",
      " g=  [[0.12877579 0.00616339 0.1255304  0.00600806]\n",
      " [0.00024357 0.21101241 0.00025781 0.22334604]] \n",
      "\n",
      " prob=  [[0.57749013 0.42250987]] \n",
      "\n",
      " probKg=  [[0.07436675 0.0035593  0.07249257 0.00346959]\n",
      " [0.00010291 0.08915483 0.00010893 0.09436591]] \n",
      "\n",
      " prob_ikn=   [[0.99861809 0.03839    0.99849968 0.03546355]\n",
      " [0.00138191 0.96161    0.00150032 0.96453645]] \n",
      "\n",
      "\n",
      "\u001b[1m \u001b[91m \u001b[4mmaximization part of the algorithm\n",
      "\u001b[0m\n",
      "mean =  [[1.10698393 3.99551759]\n",
      " [2.49926487 2.50078922]] \n",
      "\n",
      " sigma =  [[0.52891667 0.36292321]] \n",
      "\n",
      " prob =  [[0.51774283 0.48225717]] \n",
      "\n",
      " prob_ikn =  [[0.99861809 0.03839    0.99849968 0.03546355]\n",
      " [0.00138191 0.96161    0.00150032 0.96453645]]\n",
      "meanPrevious =  [[1.10698393 3.99551759]\n",
      " [2.49926487 2.50078922]]\n",
      "converge =  1\n",
      "\u001b[1m \u001b[91m \u001b[4mexpectation part of the algorithm\n",
      " \u001b[0m\n",
      "expfunc=  [6.21039150e-16 3.85927441e-01 6.24771562e-16 3.88246845e-01] \n",
      "\n",
      " g=  [[3.57008773e-01 1.16153515e-07 3.56071866e-01 1.15848690e-07]\n",
      " [7.50429033e-16 4.66333172e-01 7.54939071e-16 4.69135809e-01]] \n",
      "\n",
      " prob=  [[0.51774283 0.48225717]] \n",
      "\n",
      " probKg=  [[1.84838733e-01 6.01376495e-08 1.84353655e-01 5.99798287e-08]\n",
      " [3.61899782e-16 2.24892516e-01 3.64074780e-16 2.26244108e-01]] \n",
      "\n",
      " prob_ikn=   [[1.00000000e+00 2.67406113e-07 1.00000000e+00 2.65111049e-07]\n",
      " [1.95792179e-15 9.99999733e-01 1.97487150e-15 9.99999735e-01]] \n",
      "\n",
      "\n",
      "\u001b[1m \u001b[91m \u001b[4mmaximization part of the algorithm\n",
      "\u001b[0m\n",
      "mean =  [[1.0000008 4.       ]\n",
      " [2.5       2.5      ]] \n",
      "\n",
      " sigma =  [[0.35355509 0.35355339]] \n",
      "\n",
      " prob =  [[0.50000013 0.49999987]] \n",
      "\n",
      " prob_ikn =  [[1.00000000e+00 2.67406113e-07 1.00000000e+00 2.65111049e-07]\n",
      " [1.95792179e-15 9.99999733e-01 1.97487150e-15 9.99999735e-01]]\n",
      "meanPrevious =  [[1.0000008 4.       ]\n",
      " [2.5       2.5      ]]\n",
      "converge =  1\n",
      "\u001b[1m \u001b[91m \u001b[4mexpectation part of the algorithm\n",
      " \u001b[0m\n",
      "expfunc=  [8.53304761e-17 3.67879440e-01 8.53304765e-17 3.67879442e-01] \n",
      "\n",
      " g=  [[4.68398653e-01 1.08685717e-16 4.68398651e-01 1.08685717e-16]\n",
      " [1.08646136e-16 4.68398651e-01 1.08646137e-16 4.68398653e-01]] \n",
      "\n",
      " prob=  [[0.50000013 0.49999987]] \n",
      "\n",
      " probKg=  [[2.34199389e-01 5.43428731e-17 2.34199388e-01 5.43428728e-17]\n",
      " [5.43230538e-17 2.34199263e-01 5.43230540e-17 2.34199264e-01]] \n",
      "\n",
      " prob_ikn=   [[1.00000000e+00 2.32036909e-16 1.00000000e+00 2.32036907e-16]\n",
      " [2.31952158e-16 1.00000000e+00 2.31952161e-16 1.00000000e+00]] \n",
      "\n",
      "\n",
      "\u001b[1m \u001b[91m \u001b[4mmaximization part of the algorithm\n",
      "\u001b[0m\n",
      "mean =  [[1.  4. ]\n",
      " [2.5 2.5]] \n",
      "\n",
      " sigma =  [[0.35355339 0.35355339]] \n",
      "\n",
      " prob =  [[0.5 0.5]] \n",
      "\n",
      " prob_ikn =  [[1.00000000e+00 2.32036909e-16 1.00000000e+00 2.32036907e-16]\n",
      " [2.31952158e-16 1.00000000e+00 2.31952161e-16 1.00000000e+00]]\n",
      "meanPrevious =  [[1.  4. ]\n",
      " [2.5 2.5]]\n",
      "converge =  1\n",
      "\u001b[1m \u001b[91m \u001b[4mexpectation part of the algorithm\n",
      " \u001b[0m\n",
      "expfunc=  [8.53304763e-17 3.67879441e-01 8.53304763e-17 3.67879441e-01] \n",
      "\n",
      " g=  [[4.68398652e-01 1.08646137e-16 4.68398652e-01 1.08646137e-16]\n",
      " [1.08646137e-16 4.68398652e-01 1.08646137e-16 4.68398652e-01]] \n",
      "\n",
      " prob=  [[0.5 0.5]] \n",
      "\n",
      " probKg=  [[2.34199326e-01 5.43230684e-17 2.34199326e-01 5.43230684e-17]\n",
      " [5.43230684e-17 2.34199326e-01 5.43230684e-17 2.34199326e-01]] \n",
      "\n",
      " prob_ikn=   [[1.00000000e+00 2.31952283e-16 1.00000000e+00 2.31952283e-16]\n",
      " [2.31952283e-16 1.00000000e+00 2.31952283e-16 1.00000000e+00]] \n",
      "\n",
      "\n",
      "\u001b[1m \u001b[91m \u001b[4mmaximization part of the algorithm\n",
      "\u001b[0m\n",
      "mean =  [[1.  4. ]\n",
      " [2.5 2.5]] \n",
      "\n",
      " sigma =  [[0.35355339 0.35355339]] \n",
      "\n",
      " prob =  [[0.5 0.5]] \n",
      "\n",
      " prob_ikn =  [[1.00000000e+00 2.31952283e-16 1.00000000e+00 2.31952283e-16]\n",
      " [2.31952283e-16 1.00000000e+00 2.31952283e-16 1.00000000e+00]]\n",
      "meanPrevious =  [[1.  4. ]\n",
      " [2.5 2.5]]\n",
      "converge =  1\n",
      "\u001b[1m \u001b[91m \u001b[4mexpectation part of the algorithm\n",
      " \u001b[0m\n",
      "expfunc=  [8.53304763e-17 3.67879441e-01 8.53304763e-17 3.67879441e-01] \n",
      "\n",
      " g=  [[4.68398652e-01 1.08646137e-16 4.68398652e-01 1.08646137e-16]\n",
      " [1.08646137e-16 4.68398652e-01 1.08646137e-16 4.68398652e-01]] \n",
      "\n",
      " prob=  [[0.5 0.5]] \n",
      "\n",
      " probKg=  [[2.34199326e-01 5.43230684e-17 2.34199326e-01 5.43230684e-17]\n",
      " [5.43230684e-17 2.34199326e-01 5.43230684e-17 2.34199326e-01]] \n",
      "\n",
      " prob_ikn=   [[1.00000000e+00 2.31952283e-16 1.00000000e+00 2.31952283e-16]\n",
      " [2.31952283e-16 1.00000000e+00 2.31952283e-16 1.00000000e+00]] \n",
      "\n",
      "\n",
      "\u001b[1m \u001b[91m \u001b[4mmaximization part of the algorithm\n",
      "\u001b[0m\n",
      "mean =  [[1.  4. ]\n",
      " [2.5 2.5]] \n",
      "\n",
      " sigma =  [[0.35355339 0.35355339]] \n",
      "\n",
      " prob =  [[0.5 0.5]] \n",
      "\n",
      " prob_ikn =  [[1.00000000e+00 2.31952283e-16 1.00000000e+00 2.31952283e-16]\n",
      " [2.31952283e-16 1.00000000e+00 2.31952283e-16 1.00000000e+00]]\n",
      "meanPrevious =  [[1.  4. ]\n",
      " [2.5 2.5]]\n",
      "converge =  1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://github.com/mcdickenson/em-gaussian/blob/master/em-gaussian.py\n",
    "#https://docs.scipy.org/doc/numpy-1.13.0/user/numpy-for-matlab-users.html\n",
    "def simpleExpectationMaximization(x, K, prob, mean, sigma, threshold):\n",
    "    import math\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "\n",
    "    initializeD = np.ones((D, 1))\n",
    "    initializeN = np.ones((N, K))\n",
    "    numberOfIterations = 0\n",
    "\n",
    "    meanPrevious = mean\n",
    "    sigmaPrevious = sigma\n",
    "    probabilityPrevious = prob\n",
    "    \n",
    "    while (numberOfIterations<=5):    \n",
    "        g = np.zeros((K,N)) #initialized gaussian function for each class and size(rows) in data (N)\n",
    "        probKg = np.zeros((K,N))\n",
    "            \n",
    "        #Expectation step ***********************************************************************\n",
    "        print('\\033[1m \\033[91m \\033[4m' + \"expectation part of the algorithm\\n\", '\\033[0m')\n",
    "            \n",
    "        for k in range(K):    \n",
    "            expfunc = np.exp(-sum(np.transpose(((x-(mean[:,k]*np.ones((N, D))))**2)))/(2*(sigma[:,k]**2)))\n",
    "            g[k:] = expfunc/((np.sqrt(2*np.pi)*sigma[:,k])**D)                \n",
    "            probKg[k:] = prob[:,k]*g[k:]         \n",
    "        prob_ikn =  probKg/(np.ones((K, 1))*sum(probKg))\n",
    "            \n",
    "        print(\"expfunc= \", expfunc, \"\\n\\n\", \"g= \", g, \"\\n\\n\", \"prob= \",prob, \"\\n\\n\", \"probKg= \", probKg,\n",
    "                  \"\\n\\n\", \"prob_ikn=  \", prob_ikn, \"\\n\\n\")\n",
    "            \n",
    "        # Maximization step ******************************************************************\n",
    "        print('\\033[1m \\033[91m \\033[4m' + \"maximization part of the algorithm\\n\" + '\\033[0m')            \n",
    "        sum_prob_ikn = np.zeros((1, K))\n",
    "        sum_prob_ikn = prob_ikn.sum(axis=1)\n",
    "            \n",
    "        for k in range(K):        \n",
    "            mean[:,k] = sum(np.dot((prob_ikn[k,:].reshape(1, N)),x))/sum_prob_ikn[k] #update mean of each K  \n",
    "            diff = (x -(mean[:,k]**np.ones((N, D))))**2                        \n",
    "            sigma_numerator = np.sum((np.dot((prob_ikn[k,:].reshape(1, N)), diff)).sum(axis=0))        \n",
    "            sigma[:,k] = np.sqrt(sigma_numerator/(D*sum_prob_ikn[k])) #update the std for eac K\n",
    "            prob[:,k] = sum_prob_ikn[k]/N #update probability for each K\n",
    "                \n",
    "        #prob =  sum_prob_ikn /N # sum( sum_prob_ikn) #update the probabilities for eac K    \n",
    "        print(\"mean = \", mean,\"\\n\\n\", \"sigma = \", sigma, \"\\n\\n\", \"prob = \", prob, \"\\n\\n\",\n",
    "              \"prob_ikn = \", prob_ikn)\n",
    "        \n",
    "        #Plot the data*********************************************************\n",
    "        colors = ['tab:blue', 'tab:green','brown', 'grey'] \n",
    "        sns.scatterplot(x[:,0], x[:,1])\n",
    "        for k in range(K):\n",
    "            #plt.scatter(x[0][k], x[1][k], color = colors[k])\n",
    "            plt.scatter(mean[0][k], mean[1][k], color=colors[k])\n",
    "        \n",
    "        #Determine if the values have converged***********************************\n",
    "        print(\"meanPrevious = \", meanPrevious)\n",
    "        meanDelta = max(np.sqrt(sum((mean - meanPrevious)**2)))\n",
    "        sMean = np.mean(np.sqrt(sum(mean**2)))\n",
    "        convMean = (meanDelta <= (sMean * threshold))\n",
    "        \n",
    "        sigmaDelta = max(np.sqrt(sum((sigma - sigmaPrevious)**2)))\n",
    "        sSignma = np.mean(np.sqrt(sum(sigma**2)))\n",
    "        convSigma = (sigmaDelta <= (sSignma * threshold))\n",
    "        \n",
    "        pDelta = max(np.sqrt(sum((prob - probabilityPrevious)**2)))\n",
    "        sProbability = np.mean(np.sqrt(sum(prob**2)))\n",
    "        convProbability = (pDelta <= (sProbability * threshold))\n",
    "\n",
    "        numberOfIterations = numberOfIterations + 1\n",
    "        if (convMean & convSigma & convProbability).any():\n",
    "            converge = 1\n",
    "        else:\n",
    "            converge = 0\n",
    "        print(\"converge = \", converge)       \n",
    "#********************************************************************************\n",
    "# Run EM algorithm \n",
    "#********************************************************************************\n",
    "K = 2\n",
    "x = np.array([[1,2],[4,2],[1,3],[4,3]])\n",
    "m = np.mean(x, axis=0).reshape(-1,1) #tranpose 1d array mean in numpy\n",
    "sigma = np.std(x, axis=0, ddof=1).reshape(-1,1)\n",
    "initializeK = np.ones((1,K)) # initialize class\n",
    "print(\"m= \", m, \"\\n\", \"sigma = \", sigma, \"K = \", K)\n",
    "rnd = np.array([-0.18671, 0.72579]) # Used for example\n",
    "mean = m*initializeK + sigma*rnd\n",
    "sigma = sigma.mean() * initializeK\n",
    "prob = initializeK/K\n",
    "\n",
    "print('\\033[1m \\033[91m \\033[4m' + \"Initial values: \", \"\\n\" + '\\033[0m') \n",
    "\n",
    "print(\"K = \", K,\"\\n\\n\",\"x= \",x, \"\\n\\n\", \"mean = \", mean,\"\\n\\n\", \"sigma = \", sigma, \n",
    "      \"\\n\\n\", \"prob = \", prob, \"\\n\\n\")\n",
    "\n",
    "simpleExpectationMaximization(x, K, prob, mean, sigma, sigma[0] * 1.0e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2: Estimating the unkown parameters (mean(k), sigma(k), prob(k)) of Iris data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EM_Algorithm_IrisData(x, K, prob, mean, sigma, threshold):\n",
    "    N = x.shape[0]\n",
    "    D = x.shape[1]\n",
    "\n",
    "    initializeD = np.ones((D, 1))\n",
    "    initializeN = np.ones((N, K))\n",
    "    max_iters = 5\n",
    "    numberOfIterations = 0\n",
    "    meanPrevious = mean\n",
    "    sigmaPrevious = sigma\n",
    "    probabilityPrevious = prob\n",
    "\n",
    "    #cur_x = 3 # The algorithm starts at x=3\n",
    "    #rate = 0.01 # Learning rate\n",
    "    #precision = 0.000001 #This tells us when to stop the algorithm\n",
    "    #previous_step_size = 1 #\n",
    "    #max_iters = 10000 # maximum number of iterations\n",
    "    #iters = 0 #iteration counter\n",
    "    #df = lambda x: 2*(x+5) #Gradient of our function\n",
    "\n",
    "    #while previous_step_size > precision and iters < max_iters:\n",
    "    #prev_x = cur_x #Store current x value in prev_x\n",
    "    #cur_x = cur_x - rate * df(prev_x) #Grad descent\n",
    "    #previous_step_size = abs(cur_x - prev_x) #Change in x\n",
    "    #iters = iters+1 #iteration count\n",
    "    \n",
    "    \n",
    "    while (numberOfIterations < max_iters): \n",
    "        \n",
    "        meanPrevious = mean\n",
    "        sigmaPrevious = sigma\n",
    "        probabilityPrevious = prob\n",
    "        print(\"here\")\n",
    "        g = np.zeros((K,N)) #initialized gaussian function for each class and size(rows) in data (N)\n",
    "        probKg = np.zeros((K,N))\n",
    "            \n",
    "        #Expectation step ***********************************************************************\n",
    "        print('\\033[1m \\033[91m \\033[4m' + \"expectation part of the algorithm\\n\", '\\033[0m')\n",
    "            \n",
    "        for k in range(K):    \n",
    "            expfunc = np.exp(-sum(np.transpose(((x-(mean[:,k]*np.ones((N, D))))**2)))/(2*(sigma[:,k]**2)))\n",
    "            g[k:] = expfunc/((np.sqrt(2*np.pi)*sigma[:,k])**D)                \n",
    "            probKg[k:] = prob[:,k]*g[k:]         \n",
    "        prob_ikn =  probKg/(np.ones((K, 1))*sum(probKg))\n",
    "            \n",
    "        #print(\"prob= \",prob, \"\\n\\n\", \"probKg= \", probKg,\"\\n\\n\", \"prob_ikn=  \", prob_ikn, \"\\n\\n\")\n",
    "            \n",
    "        # Maximization step ******************************************************************\n",
    "        print('\\033[1m \\033[91m \\033[4m' + \"maximization part of the algorithm\\n\" + '\\033[0m')            \n",
    "        sum_prob_ikn = np.zeros((1, K))\n",
    "        sum_prob_ikn = prob_ikn.sum(axis=1)\n",
    "            \n",
    "        for k in range(K):        \n",
    "            mean[:,k] = sum(np.dot((prob_ikn[k,:].reshape(1, N)),x))/sum_prob_ikn[k] #update mean of each K  \n",
    "            diff = (x -(mean[:,k]**np.ones((N, D))))**2                        \n",
    "            sigma_numerator = np.sum((np.dot((prob_ikn[k,:].reshape(1, N)), diff)).sum(axis=0))        \n",
    "            sigma[:,k] = np.sqrt(sigma_numerator/(D*sum_prob_ikn[k])) #update the std for eac K\n",
    "            prob[:,k] = sum_prob_ikn[k]/N #update probability for each K (posterior)\n",
    "                \n",
    "        #prob =  sum_prob_ikn /N # sum( sum_prob_ikn) #update the probabilities for eac K    \n",
    "        print(\"mean = \", mean,\"\\n\\n\", \"sigma = \", sigma, \"\\n\\n\", \"prob = \", prob)\n",
    "        \n",
    "        #Plot the data*********************************************************\n",
    "        print(\"whatsup!!!\")\n",
    "        \n",
    "        #Determine if the values have converged***********************************\n",
    "        print(\"meanPrevious = \", meanPrevious)\n",
    "        meanDelta = max(np.sqrt(sum((mean - meanPrevious)**2)))\n",
    "        sMean = np.mean(np.sqrt(sum(mean**2)))\n",
    "        convMean = (meanDelta <= (sMean * threshold))\n",
    "        \n",
    "        sigmaDelta = max(np.sqrt(sum((sigma - sigmaPrevious)**2)))\n",
    "        sSignma = np.mean(np.sqrt(sum(sigma**2)))\n",
    "        convSigma = (sigmaDelta <= (sSignma * threshold))\n",
    "        \n",
    "        pDelta = max(np.sqrt(sum((prob - probabilityPrevious)**2)))\n",
    "        sProbability = np.mean(np.sqrt(sum(prob**2)))\n",
    "        convProbability = (pDelta <= (sProbability * threshold))\n",
    "\n",
    "        if (convMean & convSigma & convProbability).any():\n",
    "            converge = 1\n",
    "        else:\n",
    "            converge = 0\n",
    "        print(\"converge = \", converge)       \n",
    "        numberOfIterations = numberOfIterations + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "IrisData = pd.read_csv(\"C:/Users/maa5m/Desktop/2018_school/ENG685.621.81.FA19_Algorithms_for_Data_Science/HW3/input/Irisdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means=  [[5.006]\n",
      " [5.936]\n",
      " [6.588]]\n",
      "sigmas= [[0.35248969]\n",
      " [0.51617115]\n",
      " [0.63587959]]\n",
      "[[1. 1. 1.]]\n",
      "\u001b[1m \u001b[91m \u001b[4mInitial values:  \n",
      "\u001b[0m\n",
      "K =  3 \n",
      "\n",
      " x=  [[1 2]\n",
      " [4 2]\n",
      " [1 3]\n",
      " [4 3]] \n",
      "\n",
      " mean =  [[5.23954385 5.1306572  5.0101351 ]\n",
      " [6.27799184 6.11854279 5.94205527]\n",
      " [7.00930529 6.81287742 6.59545958]] \n",
      "\n",
      " sigma =  [[0.50151348 0.50151348 0.50151348]] \n",
      "\n",
      " prob =  [[0.33333333 0.33333333 0.33333333]] \n",
      "\n",
      "here\n",
      "\u001b[1m \u001b[91m \u001b[4mexpectation part of the algorithm\n",
      " \u001b[0m\n",
      "\u001b[1m \u001b[91m \u001b[4mmaximization part of the algorithm\n",
      "\u001b[0m\n",
      "mean =  [[6.6985259  6.04134645 5.31716402]\n",
      " [6.6985259  6.04134645 5.31716402]\n",
      " [6.6985259  6.04134645 5.31716402]] \n",
      "\n",
      " sigma =  [[1.04376512 1.04030766 0.96406467]] \n",
      "\n",
      " prob =  [[0.26634432 0.21852425 0.51513143]]\n",
      "whatsup!!!\n",
      "meanPrevious =  [[6.6985259  6.04134645 5.31716402]\n",
      " [6.6985259  6.04134645 5.31716402]\n",
      " [6.6985259  6.04134645 5.31716402]]\n",
      "converge =  1\n",
      "here\n",
      "\u001b[1m \u001b[91m \u001b[4mexpectation part of the algorithm\n",
      " \u001b[0m\n",
      "\u001b[1m \u001b[91m \u001b[4mmaximization part of the algorithm\n",
      "\u001b[0m\n",
      "mean =  [[6.69737536 6.05586986 5.30467235]\n",
      " [6.69737536 6.05586986 5.30467235]\n",
      " [6.69737536 6.05586986 5.30467235]] \n",
      "\n",
      " sigma =  [[1.03874304 1.04309142 0.93758042]] \n",
      "\n",
      " prob =  [[0.26917908 0.21801786 0.51280307]]\n",
      "whatsup!!!\n",
      "meanPrevious =  [[6.69737536 6.05586986 5.30467235]\n",
      " [6.69737536 6.05586986 5.30467235]\n",
      " [6.69737536 6.05586986 5.30467235]]\n",
      "converge =  1\n",
      "here\n",
      "\u001b[1m \u001b[91m \u001b[4mexpectation part of the algorithm\n",
      " \u001b[0m\n",
      "\u001b[1m \u001b[91m \u001b[4mmaximization part of the algorithm\n",
      "\u001b[0m\n",
      "mean =  [[6.69204366 6.07141063 5.29164316]\n",
      " [6.69204366 6.07141063 5.29164316]\n",
      " [6.69204366 6.07141063 5.29164316]] \n",
      "\n",
      " sigma =  [[1.03408149 1.03779871 0.91848141]] \n",
      "\n",
      " prob =  [[0.27222515 0.21861125 0.5091636 ]]\n",
      "whatsup!!!\n",
      "meanPrevious =  [[6.69204366 6.07141063 5.29164316]\n",
      " [6.69204366 6.07141063 5.29164316]\n",
      " [6.69204366 6.07141063 5.29164316]]\n",
      "converge =  1\n",
      "here\n",
      "\u001b[1m \u001b[91m \u001b[4mexpectation part of the algorithm\n",
      " \u001b[0m\n",
      "\u001b[1m \u001b[91m \u001b[4mmaximization part of the algorithm\n",
      "\u001b[0m\n",
      "mean =  [[6.68552188 6.08627628 5.2787662 ]\n",
      " [6.68552188 6.08627628 5.2787662 ]\n",
      " [6.68552188 6.08627628 5.2787662 ]] \n",
      "\n",
      " sigma =  [[1.03298567 1.02677822 0.9018205 ]] \n",
      "\n",
      " prob =  [[0.27513554 0.21983459 0.50502987]]\n",
      "whatsup!!!\n",
      "meanPrevious =  [[6.68552188 6.08627628 5.2787662 ]\n",
      " [6.68552188 6.08627628 5.2787662 ]\n",
      " [6.68552188 6.08627628 5.2787662 ]]\n",
      "converge =  1\n",
      "here\n",
      "\u001b[1m \u001b[91m \u001b[4mexpectation part of the algorithm\n",
      " \u001b[0m\n",
      "\u001b[1m \u001b[91m \u001b[4mmaximization part of the algorithm\n",
      "\u001b[0m\n",
      "mean =  [[6.67870562 6.1001701  5.26604536]\n",
      " [6.67870562 6.1001701  5.26604536]\n",
      " [6.67870562 6.1001701  5.26604536]] \n",
      "\n",
      " sigma =  [[1.03498459 1.0111454  0.88624235]] \n",
      "\n",
      " prob =  [[0.27784834 0.22152883 0.50062284]]\n",
      "whatsup!!!\n",
      "meanPrevious =  [[6.67870562 6.1001701  5.26604536]\n",
      " [6.67870562 6.1001701  5.26604536]\n",
      " [6.67870562 6.1001701  5.26604536]]\n",
      "converge =  1\n"
     ]
    }
   ],
   "source": [
    "#********************************************************************************\n",
    "# Run EM algorithm \n",
    "#********************************************************************************\n",
    "K = 3 #number of classes\n",
    "num_features = 4\n",
    "\n",
    "data = IrisData[['sepallength']]#,'sepalwidth','petallength','petalwidth']].values\n",
    "#data = IrisData[['petallength','petalwidth']].values ##remove headers\n",
    "class_id = IrisData['class'].values\n",
    "encoder = LabelEncoder()\n",
    "label_encoder = encoder.fit(class_id)\n",
    "class_id = label_encoder.transform(class_id) + 1\n",
    "label_dict = {1: 'Setosa', 2: 'Versicolor', 3:'Virginica'}\n",
    "\n",
    "#calculate the mean of each feature per class\n",
    "mean_vectors = []\n",
    "for claz in range(1,4):\n",
    "    mean_vectors.append(np.mean(data[class_id==claz], axis=0))\n",
    "means = np.array(mean_vectors)\n",
    "print(\"means= \",means)\n",
    "\n",
    "#calculate the sigma for each feature per class\n",
    "sigma_vectors = []\n",
    "for claz in range(1,4):\n",
    "    sigma_vectors.append(np.std(data[class_id==claz], axis=0, ddof=1))\n",
    "sigmas = np.array(sigma_vectors)\n",
    "print(\"sigmas=\", sigmas)\n",
    "\n",
    "#create covariance matrix for each class\n",
    "#covmatrix = []\n",
    "#for i in range(K):\n",
    "#    covmatrix.append(make_spd_matrix(data.shape[1]))\n",
    "#covmatrix = np.array(covmatrix)\n",
    "#print(\"covmatrix = \",covmatrix)\n",
    "\n",
    "initializeK = np.ones((1,K)) # initialize 1x2 matrix \n",
    "print(initializeK)\n",
    "\n",
    "rnd = np.random.rand(1,K) # Used for example\n",
    "mean = means*initializeK + sigmas*rnd\n",
    "sigma = sigmas.mean() * initializeK\n",
    "prob = initializeK/K\n",
    "\n",
    "data = np.array(data) #algorithm expects an array\n",
    "\n",
    "print('\\033[1m \\033[91m \\033[4m' + \"Initial values: \", \"\\n\" + '\\033[0m') \n",
    "\n",
    "print(\"K = \", K,\"\\n\\n\",\"x= \",x, \"\\n\\n\", \"mean = \", mean,\"\\n\\n\", \"sigma = \", sigma, \"\\n\\n\", \"prob = \", prob, \"\\n\")\n",
    "\n",
    "\n",
    "EM_Algorithm_IrisData(data, K, prob, mean, sigma, sigma[0] * 1.0e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = {'Iris-setosa':'r', 'Iris-versicolor':'g', 'Iris-virginica':'b'}\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(IrisData.shape[0]):\n",
    "    ax.scatter(IrisData['petallength'][i], IrisData['petalwidth'][i],color=colors[IrisData['class'][i]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
